{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9423  0.9397  0.9369  0.9300  0.9377  0.9373  0.0041  \n",
      "MAE (testset)     0.7409  0.7424  0.7389  0.7317  0.7404  0.7389  0.0038  \n",
      "Fit time          10.69   10.10   10.65   10.83   10.60   10.58   0.25    \n",
      "Test time         0.39    0.35    0.32    0.34    0.30    0.34    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94226779, 0.93968873, 0.93685693, 0.93004769, 0.93774583]),\n",
       " 'test_mae': array([0.74092175, 0.74242735, 0.73894886, 0.73165335, 0.74037709]),\n",
       " 'fit_time': (10.69029712677002,\n",
       "  10.10060429573059,\n",
       "  10.65111517906189,\n",
       "  10.834086418151855,\n",
       "  10.600472211837769),\n",
       " 'test_time': (0.3923370838165283,\n",
       "  0.34967613220214844,\n",
       "  0.3150451183319092,\n",
       "  0.33876800537109375,\n",
       "  0.29660820960998535)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9436260979584182"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.fit(trainset).test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1e6a84b2048>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import Dataset\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "algo = KNNBasic()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 4.06   {'actual_k': 40, 'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "uid = str(196) # raw user id (as in the ratings file).\n",
    "iid = str(302) # raw item id (as in the ratings file). \n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluating RMSE, MAE of algorithm BaselineOnly on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9447  0.9368  0.9502  0.9432  0.9461  0.9442  0.0044  \n",
      "MAE (testset)     0.7493  0.7426  0.7520  0.7483  0.7499  0.7484  0.0031  \n",
      "Fit time          0.33    0.33    0.34    0.36    0.34    0.34    0.01    \n",
      "Test time         0.21    0.29    0.30    0.21    0.28    0.26    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.94466375, 0.93684402, 0.950226  , 0.94317809, 0.94614659]),\n",
       " 'test_mae': array([0.74930371, 0.74261914, 0.75201811, 0.74828497, 0.74989178]),\n",
       " 'fit_time': (0.33083415031433105,\n",
       "  0.33434057235717773,\n",
       "  0.3365015983581543,\n",
       "  0.3625752925872803,\n",
       "  0.3367500305175781),\n",
       " 'test_time': (0.2148122787475586,\n",
       "  0.2861621379852295,\n",
       "  0.3018968105316162,\n",
       "  0.21378350257873535,\n",
       "  0.27929234504699707)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# path to dataset file\n",
    "file_path = os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/u.data')\n",
    "\n",
    "# As we're loading a custom dataset, we need to define a reader.\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "\n",
    "cross_validate(BaselineOnly(), data, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.98763616, 1.95012775]),\n",
       " 'test_mae': array([1.73891565, 1.83786776]),\n",
       " 'fit_time': (0.0005283355712890625, 0.0),\n",
       " 'test_time': (0.0, 0.0005023479461669922)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "ratings_dict = {'itemID': [1, 1, 1, 2, 2],\n",
    "               'userID': [9, 32, 2, 45, 'user_foo'],\n",
    "               'rating': [3, 2, 4, 3, 1]}\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "cross_validate(NormalPredictor(), data, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9477\n",
      "RMSE: 0.9472\n",
      "RMSE: 0.9435\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    \n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9521\n",
      "RMSE: 0.9378\n",
      "RMSE: 0.9327\n",
      "RMSE: 0.9331\n",
      "RMSE: 0.9336\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import PredefinedKFold\n",
    "\n",
    "# path to dataset folder\n",
    "files_dir = os.path.expanduser('~/.surprise_data/ml-100k/ml-100k/')\n",
    "\n",
    "# This time, we'll use the built-in reader.\n",
    "reader = Reader('ml-100k')\n",
    "\n",
    "# folds_files is a list of tuples containing file paths:\n",
    "# [(u1.base, u1.test), (u2.base, u2.test), ... (u5.base, u5.test)]\n",
    "train_file = files_dir + 'u%d.base'\n",
    "test_file = files_dir + 'u%d.test'\n",
    "folds_files = [(train_file % i, test_file % i) for i in (1, 2, 3, 4, 5)]\n",
    "\n",
    "data = Dataset.load_from_folds(folds_files, reader=reader)\n",
    "pkf = PredefinedKFold()\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in pkf.split(data):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Use movielens-100K\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(gs.cv_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
